\chapter{Middleware and service}

\section{Cloud and Edge Computing}
\subsection{Descriptive}


The Cloud and Edge Computing course, taught by Dr. Sami YANGUI, explores key concepts and technologies related to distributed computing, cloud computing, and edge computing. This course is essential for students specializing in Innovative Smart Systems, as it covers the fundamentals needed to understand how Internet of Things (IoT) systems interact with cloud and edge architectures, thus optimizing data processing and management.

Key concepts include:

Distributed Computing: This approach uses multiple interconnected components to work together in a single environment, with coordinated actions to achieve common goals. These systems help optimize communication and resource sharing within IoT applications.

Cloud Computing: This model relies on access to a vast pool of virtualized resources, available on demand, with a "pay-as-you-go" billing model. The cloud offers great flexibility for IoT infrastructure and applications, reducing operational costs.

Edge Computing: This technique brings data processing closer to the sources, reducing latency and enabling real-time processing. Edge computing is especially relevant for IoT applications requiring high responsiveness, such as predictive maintenance, fleet management, or autonomous navigation systems.

The course also covers virtualization and the role of hypervisors in enabling the simultaneous operation of multiple operating systems on a single physical infrastructure, which is crucial for resource management in cloud and edge environments.

\subsection{Technical}

Technically, the course delves into the architectures needed to set up cloud and edge systems suitable for the constraints of IoT applications. The concept of virtualization is central, particularly with the use of type-1 (bare-metal) and type-2 (hosted) hypervisors, which allow for flexible and efficient resource allocation. These hypervisors also ensure process isolation, reducing the risk of conflicts and optimizing security.

One key technical aspect of the course is cloud federation and the portability of applications between different environments. Through federation, multiple cloud services can collaborate to better manage load spikes. For example, in fleet management applications, a hybrid cloud infrastructure can dynamically distribute tasks between the centralized cloud and edge nodes to ensure continuous availability and low latency.

The practical work allows students to deepen their use of containers (such as with Docker) and cluster management via Kubernetes. As part of the lab project, students set up a hybrid cloud-edge architecture capable of handling the mobility and dynamic availability of edge nodes, simulating events like road accidents or construction sites. The goal is to maintain reliable service throughout a journey by replicating services across the network and migrating services between nodes when necessary.

Finally, the course covers deployment models, such as IaaS (Infrastructure as a Service), PaaS (Platform as a Service), and SaaS (Software as a Service), which offer varying levels of control and flexibility. Students learn to choose the appropriate model based on the specific needs of IoT applications, as well as how to design scalable and autonomous services to optimize costs and performance.

\section{Analytical Part}
Voici le contenu de la premi√®re section.


